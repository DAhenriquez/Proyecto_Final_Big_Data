Proyecto Final Big Data: E-Commerce Analytics Pipeline

**Asignatura:** Big Data  
**Estudiante:** Diego A. Henr√≠quez N√∫√±ez
**Opci√≥n del Proyecto:** B (Pipeline Anal√≠tico Batch con Spark + DuckDB)

---

## Descripci√≥n del Proyecto

Este proyecto implementa una arquitectura de datos moderna para analizar el comportamiento de usuarios en un e-commerce multicategor√≠a. El objetivo es procesar millones de registros de interacciones (vistas, carritos, compras) para extraer valor de negocio mediante herramientas de Big Data.

El flujo de trabajo transforma datos crudos (CSV comprimidos) en un **Data Lake particionado** optimizado para consultas anal√≠ticas de alta velocidad.

## Arquitectura de la Soluci√≥n

El pipeline sigue un dise√±o por capas:

1.  **Capa de Ingesta (Bronze):** Lectura masiva de archivos `.csv.gz` utilizando **Apache Spark**.
2.  **Capa de Procesamiento (Silver):** Limpieza, tipado y particionamiento de datos por fecha (`event_date`) almacenados en formato **Parquet**.
3.  **Capa de An√°lisis (Gold):** Consultas OLAP de alto rendimiento utilizando **DuckDB** (lectura *Zero-Copy*).
4.  **Capa de Visualizaci√≥n:** Dashboard interactivo integrado en Jupyter Notebook usando `ipywidgets` y `matplotlib`.

#Requisitos e Instalaci√≥n

Prerrequisitos
1. -Python 3.8+
2.  Java (JDK 8, 11 o 17/21): Necesario para ejecutar Apache Spark. Aseg√∫rate de tener configurada la variable de entorno JAVA_HOME.

#Instalaci√≥n de Librer√≠as

Ejecuta el siguiente comando para instalar las dependencias:
pip install pyspark duckdb pandas matplotlib ipywidgets

#¬øC√≥mo Ejecutar el proyecto?
Abre una terminal o Anaconda Prompt en la carpeta del proyecto.
Inicia Jupyter Lab o Jupyter Notebook:

-jupyter notebook

Abre el archivo notebook_proyecto_final.ipynb.

Ejecuta las celdas en orden secuencial.
1. Etapa 1: Spark procesar√° los archivos CSV y crear√° la carpeta silver_lake.
2. Etapa 2: DuckDB realizar√° los an√°lisis sobre los archivos Parquet.
3. Etapa 3: Al final del notebook, se renderizar√° el Dashboard Interactivo.

#Cr√©ditos y Dataset
Dataset Original: eCommerce behavior data from multi category store (Kaggle)

## üì¶ Estructura del Repositorio

Deber√≠as tener esta estructura para ejecutar el proyecto. Principalmente tener los dataset en la carpeta csv_data, las dem√°s carpetas se crear√°n al ejecutar el c√≥digo
Por razones del tama√±o del dataset, este repositorio solo cuenta con README.md y el .ipynb.

```text
/ (Ra√≠z de la entrega)
‚îú‚îÄ‚îÄ README.md                  # Este archivo (Instrucciones)
‚îî‚îÄ‚îÄ Trabajo final              # ARCHIVO DEL PROYECTO 
    ‚îÇ
    ‚îú‚îÄ‚îÄ notebook_proyecto_final.ipynb   # Notebook principal con todo el c√≥digo
    ‚îú‚îÄ‚îÄ csv_data/                       # Datos Crudos (Archivos .csv.gz originales)
    ‚îú‚îÄ‚îÄ bronze_lake/                    # Capa Bronze (Conversion directa a Parquet)
    ‚îî‚îÄ‚îÄ silver_lake/                    # Capa Silver (Datos limpios y particionados)



