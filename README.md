Proyecto Final Big Data: E-Commerce Analytics Pipeline

**Asignatura:** Big Data  
**Estudiante:** Diego A. HenrÃ­quez NÃºÃ±ez
**OpciÃ³n del Proyecto:** B (Pipeline AnalÃ­tico Batch con Spark + DuckDB)

---

## DescripciÃ³n del Proyecto

Este proyecto implementa una arquitectura de datos moderna para analizar el comportamiento de usuarios en un e-commerce multicategorÃ­a. El objetivo es procesar millones de registros de interacciones (vistas, carritos, compras) para extraer valor de negocio mediante herramientas de Big Data.

El flujo de trabajo transforma datos crudos (CSV comprimidos) en un **Data Lake particionado** optimizado para consultas analÃ­ticas de alta velocidad.

## Arquitectura de la SoluciÃ³n

El pipeline sigue un diseÃ±o por capas:

1.  **Capa de Ingesta (Bronze):** Lectura masiva de archivos `.csv.gz` utilizando **Apache Spark**.
2.  **Capa de Procesamiento (Silver):** Limpieza, tipado y particionamiento de datos por fecha (`event_date`) almacenados en formato **Parquet**.
3.  **Capa de AnÃ¡lisis (Gold):** Consultas OLAP de alto rendimiento utilizando **DuckDB** (lectura *Zero-Copy*).
4.  **Capa de VisualizaciÃ³n:** Dashboard interactivo integrado en Jupyter Notebook usando `ipywidgets` y `matplotlib`.

#Requisitos e InstalaciÃ³n

Prerrequisitos
1. -Python 3.8+
2.  Java (JDK 8, 11 o 17/21): Necesario para ejecutar Apache Spark. AsegÃºrate de tener configurada la variable de entorno JAVA_HOME.

#InstalaciÃ³n de LibrerÃ­as

Ejecuta el siguiente comando para instalar las dependencias:
pip install pyspark duckdb pandas matplotlib ipywidgets

#Â¿CÃ³mo Ejecutar el proyecto?
Abre una terminal o Anaconda Prompt en la carpeta del proyecto.
Inicia Jupyter Lab o Jupyter Notebook:

-jupyter notebook

Abre el archivo notebook_proyecto_final.ipynb.

Ejecuta las celdas en orden secuencial.
1. Etapa 1: Spark procesarÃ¡ los archivos CSV y crearÃ¡ la carpeta silver_lake.
2. Etapa 2: DuckDB realizarÃ¡ los anÃ¡lisis sobre los archivos Parquet.
3. Etapa 3: Al final del notebook, se renderizarÃ¡ el Dashboard Interactivo.

#CrÃ©ditos y Dataset
Dataset Original: eCommerce behavior data from multi category store (Kaggle)

## ðŸ“¦ Estructura del Repositorio

```text
/ (RaÃ­z de la entrega)
â”œâ”€â”€ README.md                  # Este archivo (Instrucciones)
â””â”€â”€ Trabajo final.zip          # ARCHIVO DEL PROYECTO (DESCOMPRIMIR PRIMERO)
    â”‚
    â”œâ”€â”€ notebook_proyecto_final.ipynb   # Notebook principal con todo el cÃ³digo
    â”œâ”€â”€ csv_data/                       # Datos Crudos (Archivos .csv.gz originales)
    â”œâ”€â”€ bronze_lake/                    # Capa Bronze (Conversion directa a Parquet)
    â””â”€â”€ silver_lake/                    # Capa Silver (Datos limpios y particionados)



